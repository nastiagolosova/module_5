{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2020-10-26T12:46:41.400302Z",
     "iopub.status.busy": "2020-10-26T12:46:41.399317Z",
     "iopub.status.idle": "2020-10-26T12:46:42.581426Z",
     "shell.execute_reply": "2020-10-26T12:46:42.580431Z"
    },
    "papermill": {
     "duration": 1.219772,
     "end_time": "2020-10-26T12:46:42.581597",
     "exception": false,
     "start_time": "2020-10-26T12:46:41.361825",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import sys\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from tqdm.notebook import tqdm\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import re\n",
    "from scipy import stats\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import ttest_ind\n",
    "import seaborn as sns\n",
    "from sklearn.feature_selection import f_classif, mutual_info_classif\n",
    "from pandas import Series\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, StackingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2020-10-26T12:46:42.646795Z",
     "iopub.status.busy": "2020-10-26T12:46:42.645765Z",
     "iopub.status.idle": "2020-10-26T12:46:42.649793Z",
     "shell.execute_reply": "2020-10-26T12:46:42.650407Z"
    },
    "papermill": {
     "duration": 0.040034,
     "end_time": "2020-10-26T12:46:42.650603",
     "exception": false,
     "start_time": "2020-10-26T12:46:42.610569",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('Python       :', sys.version.split('\\n')[0])\n",
    "print('Numpy        :', np.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2020-10-26T12:46:42.716039Z",
     "iopub.status.busy": "2020-10-26T12:46:42.715184Z",
     "iopub.status.idle": "2020-10-26T12:46:47.852433Z",
     "shell.execute_reply": "2020-10-26T12:46:47.851661Z"
    },
    "papermill": {
     "duration": 5.172536,
     "end_time": "2020-10-26T12:46:47.852593",
     "exception": false,
     "start_time": "2020-10-26T12:46:42.680057",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# зафиксируем версию пакетов, чтобы эксперименты были воспроизводимы:\n",
    "!pip freeze > requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-26T12:46:47.919419Z",
     "iopub.status.busy": "2020-10-26T12:46:47.918168Z",
     "iopub.status.idle": "2020-10-26T12:46:47.922267Z",
     "shell.execute_reply": "2020-10-26T12:46:47.921365Z"
    },
    "papermill": {
     "duration": 0.039842,
     "end_time": "2020-10-26T12:46:47.922434",
     "exception": false,
     "start_time": "2020-10-26T12:46:47.882592",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# всегда фиксируйте RANDOM_SEED, чтобы ваши эксперименты были воспроизводимы!\n",
    "RANDOM_SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "def mape(y_true, y_pred):\n",
    "    return np.mean(np.abs((y_pred-y_true)/y_true))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.028837,
     "end_time": "2020-10-26T12:46:47.981435",
     "exception": false,
     "start_time": "2020-10-26T12:46:47.952598",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-26T12:46:48.05046Z",
     "iopub.status.busy": "2020-10-26T12:46:48.049412Z",
     "iopub.status.idle": "2020-10-26T12:46:48.052578Z",
     "shell.execute_reply": "2020-10-26T12:46:48.051917Z"
    },
    "papermill": {
     "duration": 0.039969,
     "end_time": "2020-10-26T12:46:48.052728",
     "exception": false,
     "start_time": "2020-10-26T12:46:48.012759",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "VERSION    = 16\n",
    "DIR_TRAIN  = '../input/parsing-all-moscow-auto-ru-09-09-2020/' # подключил к ноутбуку внешний датасет\n",
    "DIR_TEST   = '../input/sf-dst-car-price-prediction/'\n",
    "VAL_SIZE   = 0.20   # 20%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# посмотрим какие столбцы нам нужны \n",
    "test = pd.read_csv(DIR_TEST+'test.csv')\n",
    "print('Кол-во столбцов теста:', test.shape[1])\n",
    "print('Названия столбцов теста:', list(test.columns))\n",
    "\n",
    "# вывод всех столбцов датафрейма\n",
    "pd.set_option('display.max_columns', None)\n",
    "test.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.030254,
     "end_time": "2020-10-26T12:46:48.112586",
     "exception": false,
     "start_time": "2020-10-26T12:46:48.082332",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-26T12:46:48.179769Z",
     "iopub.status.busy": "2020-10-26T12:46:48.178918Z",
     "iopub.status.idle": "2020-10-26T12:46:48.924574Z",
     "shell.execute_reply": "2020-10-26T12:46:48.925184Z"
    },
    "papermill": {
     "duration": 0.783211,
     "end_time": "2020-10-26T12:46:48.925418",
     "exception": false,
     "start_time": "2020-10-26T12:46:48.142207",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!ls '../input'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "execution": {
     "iopub.execute_input": "2020-10-26T12:46:49.007668Z",
     "iopub.status.busy": "2020-10-26T12:46:49.006762Z",
     "iopub.status.idle": "2020-10-26T12:47:02.121152Z",
     "shell.execute_reply": "2020-10-26T12:47:02.120434Z"
    },
    "papermill": {
     "duration": 13.16556,
     "end_time": "2020-10-26T12:47:02.12133",
     "exception": false,
     "start_time": "2020-10-26T12:46:48.95577",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(DIR_TRAIN+'all_auto_ru_09_09_2020.csv') # датасет для обучения модели\n",
    "test = pd.read_csv(DIR_TEST+'test.csv')\n",
    "sample_submission = pd.read_csv(DIR_TEST+'sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-26T12:47:02.22557Z",
     "iopub.status.busy": "2020-10-26T12:47:02.21916Z",
     "iopub.status.idle": "2020-10-26T12:47:02.245921Z",
     "shell.execute_reply": "2020-10-26T12:47:02.246559Z"
    },
    "papermill": {
     "duration": 0.09378,
     "end_time": "2020-10-26T12:47:02.246755",
     "exception": false,
     "start_time": "2020-10-26T12:47:02.152975",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-26T12:47:02.317036Z",
     "iopub.status.busy": "2020-10-26T12:47:02.316251Z",
     "iopub.status.idle": "2020-10-26T12:47:02.50135Z",
     "shell.execute_reply": "2020-10-26T12:47:02.501985Z"
    },
    "papermill": {
     "duration": 0.22352,
     "end_time": "2020-10-26T12:47:02.502166",
     "exception": false,
     "start_time": "2020-10-26T12:47:02.278646",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Кол-во столбцов train:', train.shape[1])\n",
    "print('Названия столбцов train:', list(train.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I will rename the column in train so that it has the same name as in test\n",
    "train.rename(columns={'model': 'model_name'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I will add vendor column to train:\n",
    "euro = ['BMW', 'VOLKSWAGEN', 'MERCEDES', 'AUDI', 'SKODA', 'VOLVO']\n",
    "train['vendor'] = train['brand'].apply(lambda x: 'EUROPEAN' if x in euro else 'JAPANESE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I will delete test columns that are not in train\n",
    "test_columns = list(test.columns)\n",
    "train_columns = list(train.columns)\n",
    "for i in test_columns:\n",
    "    if i not in train_columns:\n",
    "        test.drop(columns=i, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I will also delete train columns that are not in test, except price:\n",
    "train.drop(columns=['Комплектация', 'start_date', 'hidden'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking\n",
    "print(len(train.columns), len(test.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# there are extra brands in train\n",
    "train['brand'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['brand'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I will only keep records for the same brands we have in test\n",
    "brands = test['brand'].unique()\n",
    "train = train[train['brand'].isin(brands)]\n",
    "train['brand'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross-checking if there are any different models in train and test\n",
    "audi_models = test.loc[test['brand'] == 'AUDI'].model_name.unique()\n",
    "for i in train.loc[train['brand'] == 'AUDI'].model_name.unique():\n",
    "    if i not in audi_models:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audi_models = test.loc[test['brand'] == 'AUDI'].model_name.unique()\n",
    "for i in audi_models:\n",
    "    if i not in train.loc[train['brand'] == 'AUDI'].model_name.unique():\n",
    "    \n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quick googling shows it is the same model, so I will rename it in train:\n",
    "train['model_name'] = train['model_name'].str.replace('Q3_SPORTBACK', 'RSQ3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will do the same procedure for the remaining brands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another name for corolla II is tercel, which is present in train, so I will rename it. The same applies to WILL\n",
    "# and WILL_Cypha\n",
    "train['model_name'] = train['model_name'].str.replace('TERCEL', 'COROLLA_II')\n",
    "train['model_name'] = train['model_name'].str.replace('WILL', 'WILL_CYPHA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# joining train and test together to process\n",
    "train['sample'] = 1 # mark train\n",
    "test['sample'] = 0 # mark test\n",
    "test['price'] = 0 # filling in \"default\" column with zeros as it is the value to be predicted\n",
    "\n",
    "data = test.append(train, sort=False).reset_index(drop=True) # join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target\n",
    "y = train['price']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.033402,
     "end_time": "2020-10-26T12:47:02.866506",
     "exception": false,
     "start_time": "2020-10-26T12:47:02.833104",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I will take hourse powers from info in \"name\". I am making life more difficult for myself because I wanted to see how I\n",
    "# can work with regex because I hardly had any practice with it\n",
    "data.name = data.name.str.findall(r'\\(.+?л.с.')\n",
    "data.name = data.name.apply(lambda x: str(x))\n",
    "data.name = data.name.apply(lambda x: x[3:6])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#some of the cells turned out to be empty, so I will delete those\n",
    "data = data[data.name != '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# and change data type to int\n",
    "data.name = data.name.astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# because columns related to customs clearance and condition have only one type of entry, I will delete them:\n",
    "data.drop(columns=['Состояние', 'Таможня'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.Владение.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Because the column describing length of ownership has mostly nans, I will delete it too\n",
    "data.drop(columns=['Владение'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I will also delete description, and enginePower because I have this information already\n",
    "data.drop(columns=['description', 'enginePower'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I need to make entries from train and test identical:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"vehicleTransmission\"].replace({\"роботизированная\": \"ROBOT\", \"механическая\": \"MECHANICAL\",\\\n",
    "                                     \"автоматическая\": \"AUTOMATIC\", \"вариатор\": \"VARIATOR\"}, inplace=True)\n",
    "data[\"ПТС\"].replace({\"Оригинал\": \"ORIGINAL\", \"Дубликат\": \"DUPLICATE\"}, inplace=True)\n",
    "data[\"Руль\"].replace({\"Левый\": \"LEFT\", \"Правый\": \"RIGHT\"}, inplace=True)\n",
    "data[\"Владельцы\"].replace({\"3 или более\": \"3.0\", \"2\\xa0владельца\": \"2.0\", \"1\\xa0владелец\": \"1.0\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.Владельцы = data.Владельцы.astype('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I will also rename values in \"color\" based on the result of quick googling for color codes\n",
    "data[\"color\"].replace({\"040001\": \"чёрный\", \"EE1D19\": \"красный\", \"0000CC\": \"синий\",\n",
    "                       \"CACECB\": \"серебристый\", \"007F00\": \"зелёный\", \"FAFBFB\": \"белый\",\n",
    "                       \"97948F\": \"серый\", \"22A0F8 \": \"голубой\", \"660099\": \"фиолетовый\",\n",
    "                       \"200204 \": \"чёрный\", \"C49648\": \"бежевый\", \"DEA522\": \"жёлтый\",\n",
    "                       \"4A2197\": \"фиолетовый\",\"FFD600\": \"золотистый\",\"FF8649\": \"оранжевый\",\n",
    "                       \"FFC0CB\": \"розовый\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"engineDisplacement\"].replace({'1.2 LTR': '1.2', '1.6 LTR': '1.6', '1.8 LTR': '1.8', '2.0 LTR': '2.0',\n",
    "                                    '1.4 LTR': '1.4', '1.3 LTR': '1.3', '1.0 LTR': '1.0', '3.6 LTR': '3.6', \n",
    "                                    '1.5 LTR': '1.5', '1.9 LTR': '1.9', '2.8 LTR': '2.8', '1.1 LTR': '1.1',\n",
    "                                    '2.5 LTR': '2.5', '4.2 LTR': '4.2', '3.0 LTR': '3.0', '4.0 LTR': '4.0',\n",
    "                                    '5.9 LTR': '5.9', '2.7 LTR': '2.7', '3.1 LTR': '3.1', '2.4 LTR': '2.4', \n",
    "                                    '5.2 LTR': '5.2', '3.2 LTR': '3.2', '4.1 LTR': '4.1', '6.3 LTR': '6.3',\n",
    "                                    '2.3 LTR': '2.3', '6.0 LTR': '6.0', '2.2 LTR': '2.2', '3.7 LTR': '3.7', \n",
    "                                    '2.9 LTR': '2.9', '5.0 LTR': '5.0', '3.3 LTR': '3.3', '2.1 LTR': '2.1',\n",
    "                                    '2.6 LTR': '2.6', '3.5 LTR': '3.5', '1.7 LTR': '1.7', '0.7 LTR': '0.7',\n",
    "                                    '4.4 LTR': '4.4', '4.8 LTR': '4.8', '5.4 LTR':'5.4', '6.6 LTR': '6.6', \n",
    "                                    '4.9 LTR': '4.9', '3.8 LTR': '3.8', '3.4 LTR': '3.4', '3.9 LTR': '3.9', \n",
    "                                    '4.6 LTR': '4.6', '5.6 LTR': '5.6', '4.5 LTR': '4.5', '5.5 LTR': '5.5',\n",
    "                                    '6.2 LTR': '6.2', '4.7 LTR': '4.7', '4.3 LTR': '4.3', '5.8 LTR': '5.8',\n",
    "                                    '5.3 LTR': '5.3', '5.7 LTR': '5.7'\n",
    "                                    }, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# there is some correlation between the number of owners and production date\n",
    "data[['Владельцы', 'productionDate']].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[data.productionDate > 2018].Владельцы.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[data.Владельцы.isna()].productionDate.unique()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[data.productionDate >= 2018].Владельцы.mode()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I think it's safe to fill nans with 1.0, as it is the most frequent value for the years that don't have the owner entry\n",
    "data.Владельцы.fillna(1.0, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill in ПТС with most frequen value\n",
    "data['ПТС'].fillna(data['ПТС'].mode, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# and drop the rows without price:\n",
    "data.dropna(subset=['price'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_cols = ['vendor', 'Руль']\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "for column in bin_cols:\n",
    "    data[column] = label_encoder.fit_transform(data[column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for some reason it didn't work with ПТС column and I kept getting \"'Series' objects are mutable, thus they cannot be hashed\"\n",
    "# I decided to replace that column with a different now. Simple renaming also didn't work\n",
    "# If you know why it happened to that column only, let me know\n",
    "data['certificate'] = data[\"ПТС\"].apply(lambda x: 1 if x == 'ORIGINAL' else 0) \n",
    "data.drop(columns=['ПТС'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I will create a new column showing how new the model was at the date of production, because a new model can be seen by\n",
    "# a potential buyer as less reliable\n",
    "data['how_new'] = data.productionDate - data.modelDate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I will also create a new column showing the age of the car\n",
    "data['age'] = (2021 - data['productionDate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# and another one showing how many kms it made in a one year\n",
    "data['per_year'] = data['age']/ data['mileage']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will create some polynomial features, because based on what I read \"typically linear algorithms, such as linear regression and logistic regression, respond well to the use of polynomial input variables\".and \"adding polynomial terms to the model can be an effective way of allowing the model to identify nonlinear patterns.\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These features proved to be detrimental to the model, so I ended up excluding them, but please check if they've been created correctly anyway"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#poly_features = data.query('sample == 1')[['mileage', 'productionDate']]\n",
    "#poly_features_test = data.query('sample == 0')[['mileage', 'productionDate']]\n",
    "\n",
    "#imputer = SimpleImputer(strategy = 'median')\n",
    "\n",
    "#poly_features = imputer.fit_transform(poly_features)\n",
    "#poly_features_test = imputer.transform(poly_features_test)\n",
    "\n",
    "\n",
    "#poly_transformer = PolynomialFeatures(degree = 3)\n",
    "\n",
    "#poly_transformer.fit(poly_features)\n",
    "#poly_features = poly_transformer.transform(poly_features)\n",
    "#poly_features_test = poly_transformer.transform(poly_features_test)\n",
    "#print('Polynomial Features shape: ', poly_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#poly_transformer.get_feature_names(input_features = ['mileage', 'productionDate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#poly_features = pd.DataFrame(poly_features, \n",
    "#                             columns = poly_transformer.get_feature_names(['mileage', 'productionDate']))\n",
    "#poly_features_test = pd.DataFrame(poly_features_test, \n",
    "#                             columns = poly_transformer.get_feature_names(['mileage', 'productionDate']))\n",
    "#joined = pd.concat([poly_features,poly_features_test],ignore_index=True)\n",
    "#df = pd.concat(\n",
    "#    [\n",
    "#        data.reset_index(drop=True),\n",
    "#        joined.reset_index(drop=True),\n",
    "#    ],\n",
    "#    axis=1,\n",
    "#    ignore_index=True,\n",
    "#)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## I need to join these two set of features with data so that nans don't appear\n",
    "#concatenated_dataframes_columns = [\n",
    "#    list(data.columns),\n",
    "#    list(joined.columns),\n",
    "#    ]\n",
    "    \n",
    "#flatten = lambda nested_lists: [item for sublist in nested_lists for item in sublist]\n",
    "\n",
    "#df.columns = flatten(concatenated_dataframes_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## it gave me a 2 pairs of columns with the same name, so I will rename them\n",
    "#df.columns = ['bodyType', 'brand', 'color', 'engineDisplacement', 'fuelType', 'mileage', 'modelDate', 'model_name',\n",
    "#              'name', 'numberOfDoors', 'productionDate', 'vehicleConfiguration', 'vehicleTransmission', 'vendor',\n",
    "#              'Владельцы', 'Привод','Руль', 'sample', 'price', 'certificate', 'how_new', 'age', 'per_year', '1',\n",
    "#              'mileage_2', 'productionDate_2', 'mileage^2', 'mileage productionDate', 'productionDate^2', 'mileage^3',\n",
    "#              'mileage^2 productionDate', 'mileage productionDate^2', 'productionDate^3']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for the ease of use in exploratory analysis I will split the features into types:\n",
    "#bin_cols = ['vendor', 'Руль', 'certificate']\n",
    "#num_cols = ['mileage', 'modelDate', 'name', 'numberOfDoors', 'productionDate', 'Владельцы', 'how_new',\n",
    "#            'mileage_2', 'productionDate_2', 'mileage^2', 'mileage productionDate', 'productionDate^2', \n",
    "#            'mileage^3', 'mileage^2 productionDate', 'mileage productionDate^2', 'productionDate^3']\n",
    "#cat_cols = ['bodyType', 'brand', 'color', 'engineDisplacement', 'fuelType', 'model_name', 'vehicleConfiguration',\n",
    "#           'vehicleTransmission', 'Привод']\n",
    "# engineDisplacement has to be a numeric value, but there also non-numeric values present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for the ease of use in exploratory analysis I will split the features into types:\n",
    "bin_cols = ['vendor', 'Руль', 'certificate']\n",
    "num_cols = ['mileage', 'modelDate', 'name', 'numberOfDoors', 'productionDate', 'Владельцы', 'how_new',]\n",
    "cat_cols = ['bodyType', 'brand', 'color', 'engineDisplacement', 'fuelType', 'model_name', 'vehicleConfiguration',\n",
    "           'vehicleTransmission', 'Привод']\n",
    "# engineDisplacement has to be a numeric value, but there also non-numeric values present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's see how binary features correlate with the target:\n",
    "vendor = data.vendor.to_numpy()\n",
    "wheel = data.Руль.to_numpy()\n",
    "certificate = data.certificate.to_numpy()\n",
    "price = data.price\n",
    "\n",
    "print(f'vendor = {stats.pointbiserialr(price, vendor)}, wheel = {stats.pointbiserialr(price, wheel)}, \\\n",
    "certificate = {stats.pointbiserialr(price, certificate)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the catecorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I will only look at correlation of train data with price\n",
    "def get_boxplot(column):\n",
    "    fig, ax = plt.subplots(figsize = (12, 8))\n",
    "    sns.boxplot(x=column, y='price', \n",
    "                data=data.query('sample == 1').loc[data.query('sample == 1').loc[:, column].isin(data.query('sample == 1').loc[:, column].value_counts().index[:10])],\n",
    "               ax=ax)\n",
    "    plt.xticks(rotation=0)\n",
    "    ax.set_title('Boxplot for ' + column)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in cat_cols:\n",
    "    get_boxplot(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a few outliers, especially for Mercedes, so  iwill examine this brand more closely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[(data.brand == 'MERCEDES') & (data.price == data.price.max())]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mercedes is a pricey brand, but over 68 million is too much for this car given the current offers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data.brand == 'MERCEDES'].price.quantile(0.90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[(data.brand == 'MERCEDES') & (data.price > 7051258.40000001)].model_name.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After looking at the current offers, prices of some models were questionable, so I will look at them in more detail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_to_check = ['A_KLASSE_AMG', 'C_KLASSE_AMG', 'E_KLASSE', 'W136']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[(data.model_name.isin(models_to_check)) & (data.price > 7051258.40000001)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given that most of the cars are new the prices make sense, except for the 2012 coupe, so I will delete this entry and the one above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop([82141, 76668])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical data and label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for colum in cat_cols:\n",
    "    data[colum] = data[colum].astype('category').cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's see the dependency between the target and categorical and binary viriables\n",
    "imp_cat = Series(mutual_info_classif(data[bin_cols + cat_cols], data['price'],\n",
    "                                     discrete_features =True), index = bin_cols + cat_cols)\n",
    "imp_cat.sort_values(inplace = True)\n",
    "imp_cat.plot(kind = 'barh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numerical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's see if numerical data is distributed normally:\n",
    "for i in data[num_cols]:\n",
    "    plt.figure()\n",
    "    sns.distplot(data[i], kde = False, rug=False)\n",
    "    plt.title(i)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking correlation of numerical variables:\n",
    "sns.heatmap(data[num_cols].corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I will drop age because it is obviously correlated with the model date:\n",
    "data.drop(columns = 'age')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's check the dependency between numerical data and target:\n",
    "imp_num = Series(f_classif(data[num_cols], data['price'])[0], index = num_cols)\n",
    "imp_num.sort_values(inplace = True)\n",
    "imp_num.plot(kind = 'barh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.035737,
     "end_time": "2020-10-26T12:47:03.826552",
     "exception": false,
     "start_time": "2020-10-26T12:47:03.790815",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "> # Preparing data for ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I will drop float columns and change all the data type to int\n",
    "data.drop(columns =['age','per_year'], inplace=True)\n",
    "data = data.astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.query('sample == 1').drop(['sample', 'price'], axis=1)\n",
    "y = data.query('sample == 1').price\n",
    "X_sub = data.query('sample == 0').drop(['sample', 'price'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=VAL_SIZE, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.037164,
     "end_time": "2020-10-26T12:47:03.997616",
     "exception": false,
     "start_time": "2020-10-26T12:47:03.960452",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Model from baseline : CatBoost\n",
    "   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.035833,
     "end_time": "2020-10-26T12:47:04.149539",
     "exception": false,
     "start_time": "2020-10-26T12:47:04.113706",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-26T12:47:04.256865Z",
     "iopub.status.busy": "2020-10-26T12:47:04.248328Z",
     "iopub.status.idle": "2020-10-26T12:48:12.17834Z",
     "shell.execute_reply": "2020-10-26T12:48:12.17762Z"
    },
    "papermill": {
     "duration": 67.991521,
     "end_time": "2020-10-26T12:48:12.178488",
     "exception": false,
     "start_time": "2020-10-26T12:47:04.186967",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = CatBoostRegressor(iterations = 5000,\n",
    "                          random_seed = RANDOM_SEED,\n",
    "                          eval_metric='MAPE',\n",
    "                          custom_metric=['R2', 'MAE'],\n",
    "                          silent=True,\n",
    "                         )\n",
    "model.fit(X_train, y_train,\n",
    "         #cat_features=cat_features_ids,\n",
    "         eval_set=(X_test, y_test),\n",
    "         verbose_eval=0,\n",
    "         use_best_model=True,\n",
    "         #plot=True\n",
    "         )\n",
    "\n",
    "model.save_model('catboost_single_model_baseline.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# оцениваем точность\n",
    "predict = model.predict(X_test)\n",
    "print(f\"Точность модели по метрике MAPE: {(mape(y_test, predict))*100:0.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Log Traget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.log(y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CatBoostRegressor(iterations = 5000,\n",
    "                          random_seed = RANDOM_SEED,\n",
    "                          eval_metric='MAPE',\n",
    "                          custom_metric=['R2', 'MAE'],\n",
    "                          silent=True,\n",
    "                         )\n",
    "model.fit(X_train, np.log1p(y_train),\n",
    "         cat_features=cat_cols,\n",
    "         eval_set=(X_test, np.log1p(y_test)),\n",
    "         verbose_eval=0,\n",
    "         use_best_model=True,\n",
    "         #plot=True\n",
    "         )\n",
    "\n",
    "model.save_model('catboost_single_model_2_baseline.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_test = np.expm1(model.predict(X_test))\n",
    "predict_submission = np.expm1(model.predict(X_sub))\n",
    "print(f\"Точность модели по метрике MAPE: {(mape(y_test, predict_test))*100:0.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This result was better than that of stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators=[\n",
    "        ('rf', RandomForestRegressor(random_state=RANDOM_SEED, \n",
    "                                      n_estimators=200, min_samples_split=2, \n",
    "                                      min_samples_leaf=2, \n",
    "                                      max_features='auto', max_depth=5, \n",
    "                                      bootstrap=True, n_jobs=-1)),\n",
    "        ('gbr', GradientBoostingRegressor(n_estimators=1000, random_state=RANDOM_SEED,  \n",
    "                                          )),\n",
    "        ('сbr',  CatBoostRegressor(iterations = 2000,\n",
    "                                   learning_rate = 0.062,\n",
    "                                   random_seed = RANDOM_SEED,\n",
    "                                   eval_metric='MAPE',\n",
    "                                   custom_metric=['R2', 'MAE'],\n",
    "                                   depth=10,\n",
    "                                   l2_leaf_reg=1)\n",
    "        )\n",
    "        ]\n",
    "\n",
    "sr = StackingRegressor(estimators=estimators,\n",
    "                       final_estimator = GradientBoostingRegressor(n_estimators=500, \n",
    "                                                                   random_state=RANDOM_SEED))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr.fit(X_train, np.log1p(y_train))\n",
    "predict_test = np.expm1(sr.predict(X_test))\n",
    "predict_submission_stacked = np.expm1(sr.predict(X_sub))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Точность модели по метрике MAPE: {(mape(y_test, predict_test))*100:0.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.085876,
     "end_time": "2020-10-26T12:48:12.734207",
     "exception": false,
     "start_time": "2020-10-26T12:48:12.648331",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-26T12:48:13.227584Z",
     "iopub.status.busy": "2020-10-26T12:48:13.226285Z",
     "iopub.status.idle": "2020-10-26T12:48:13.762529Z",
     "shell.execute_reply": "2020-10-26T12:48:13.763259Z"
    },
    "papermill": {
     "duration": 0.628302,
     "end_time": "2020-10-26T12:48:13.763488",
     "exception": false,
     "start_time": "2020-10-26T12:48:13.135186",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv(DIR_TEST + 'sample_submission.csv')\n",
    "predict_submission = pd.DataFrame(predict_submission, columns=['price'])\n",
    "sample_submission['price'] = predict_submission\n",
    "sample_submission['price'] = sample_submission['price'].fillna(sample_submission['price'].mean())\n",
    "sample_submission.to_csv(f'submission_2_v{VERSION}.csv', index=False)\n",
    "sample_submission.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
